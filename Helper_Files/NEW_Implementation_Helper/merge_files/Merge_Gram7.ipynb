{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "laughing-heating",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/3/hassa940/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging files matching pattern: ../Outer_Correlation/new_outer_correlation_results_per_section/gram7_past_tense_results-*.csv\n",
      "Found 2 files:\n",
      "  • Found gram7_past_tense_results-1.csv\n",
      "  • Found gram7_past_tense_results-2.csv\n",
      "\n",
      "Concatenating all files...\n",
      "  • Combined data: 88920 rows\n",
      "\n",
      "Created 60 canonical parameter combinations\n",
      "\n",
      "Analyzing existing combinations:\n",
      "  • Found 60 unique combinations\n",
      "  • Distribution of combination frequencies: {1482: 60}\n",
      "  • Found 1482 unique questions\n",
      "\n",
      "Building clean dataset...\n",
      "\n",
      "Final check: 60 unique combinations\n",
      "✓ Success! Exactly 60 unique combinations as expected.\n",
      "\n",
      "Successfully saved merged data to: ../Outer_Correlation/new_outer_correlation_results_per_section/gram7_past_tense_results.csv\n",
      "  • Output file size: 16.28 MB\n",
      "  • Merge operation completed successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def merge_and_clean_results(input_pattern, output_file):\n",
    "    \"\"\"\n",
    "    Merge multiple CSV files and enforce exactly 60 combinations by:\n",
    "    1. Identifying the canonical 60 combinations (5 rcond × 3 measures × 4 top@k)\n",
    "    2. Grouping by these combinations and averaging the accuracy values\n",
    "    3. Creating a clean dataset with exactly these combinations\n",
    "    \n",
    "    Args:\n",
    "        input_pattern: Glob pattern to match input files (e.g., \"*.csv\")\n",
    "        output_file: Path to save the merged and cleaned file\n",
    "    \"\"\"\n",
    "    print(f\"Merging files matching pattern: {input_pattern}\")\n",
    "    \n",
    "    # Step 1: Load all CSV files\n",
    "    all_files = sorted(glob.glob(input_pattern))\n",
    "    if not all_files:\n",
    "        print(f\"Error: No files found matching {input_pattern}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(all_files)} files:\")\n",
    "    for file in all_files:\n",
    "        print(f\"  • Found {os.path.basename(file)}\")\n",
    "    \n",
    "    # Load each file\n",
    "    all_dfs = []\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file)\n",
    "        all_dfs.append(df)\n",
    "    \n",
    "    # Step 2: Concatenate all files\n",
    "    print(\"\\nConcatenating all files...\")\n",
    "    full_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"  • Combined data: {len(full_df)} rows\")\n",
    "    \n",
    "    # Step 3: Identify the canonical 60 combinations\n",
    "    # First, get the unique values of each parameter\n",
    "    rcond_values = sorted(full_df[\"rcond\"].unique())\n",
    "    measure_values = [\"naive_cosine\", \"mahalanobis_cosine\", \"mahalanobis_shifted_cosine\"]\n",
    "    topk_values = [1, 3, 5, 10]\n",
    "    \n",
    "    # Ensure we have exactly 5 rcond values\n",
    "    if len(rcond_values) != 5:\n",
    "        print(f\"Warning: Found {len(rcond_values)} rcond values instead of 5\")\n",
    "        # Take the 5 most common rcond values\n",
    "        rcond_counts = full_df[\"rcond\"].value_counts()\n",
    "        rcond_values = list(rcond_counts.head(5).index)\n",
    "    \n",
    "    # Create the 60 canonical combinations\n",
    "    canonical_combos = []\n",
    "    for rcond in rcond_values:\n",
    "        for measure in measure_values:\n",
    "            for topk in topk_values:\n",
    "                canonical_combos.append((rcond, measure, topk))\n",
    "    \n",
    "    print(f\"\\nCreated {len(canonical_combos)} canonical parameter combinations\")\n",
    "    \n",
    "    # Step 4: Group by the key parameters and compute average accuracy\n",
    "    group_cols = [\"rcond\", \"measure\", \"top@k\"]\n",
    "    avg_accuracy = full_df.groupby(group_cols)[\"overall_accuracy\"].mean().reset_index()\n",
    "    \n",
    "    print(\"\\nAnalyzing existing combinations:\")\n",
    "    unique_combos = full_df.groupby(group_cols).size().reset_index(name=\"count\")\n",
    "    print(f\"  • Found {len(unique_combos)} unique combinations\")\n",
    "    combo_counts = unique_combos[\"count\"].value_counts().to_dict()\n",
    "    print(f\"  • Distribution of combination frequencies: {combo_counts}\")\n",
    "    \n",
    "    # Step 5: Get one representative question set for each category\n",
    "    # We'll keep all the question data, just update the accuracy values\n",
    "    question_cols = [col for col in full_df.columns if col not in \n",
    "                    [\"rcond\", \"measure\", \"top@k\", \"overall_accuracy\", \"quantile\", \"freq_subset\"]]\n",
    "    \n",
    "    # Get a representative row for each question across all parameters\n",
    "    question_key_cols = [\"word1\", \"word2\", \"word3\", \"true_word\", \"category\", \"category_type\"]\n",
    "    unique_questions = full_df[question_key_cols].drop_duplicates()\n",
    "    print(f\"  • Found {len(unique_questions)} unique questions\")\n",
    "    \n",
    "    # Step 6: Build the final dataset with exactly 60 combinations\n",
    "    print(\"\\nBuilding clean dataset...\")\n",
    "    \n",
    "    # For each canonical combination, get all matching questions with updated accuracy\n",
    "    result_parts = []\n",
    "    for rcond, measure, topk in canonical_combos:\n",
    "        # Get the accuracy for this combination\n",
    "        acc_match = avg_accuracy[\n",
    "            (avg_accuracy[\"rcond\"] == rcond) & \n",
    "            (avg_accuracy[\"measure\"] == measure) & \n",
    "            (avg_accuracy[\"top@k\"] == topk)\n",
    "        ]\n",
    "        \n",
    "        if len(acc_match) == 0:\n",
    "            print(f\"  • Warning: No data found for combination: rcond={rcond}, measure={measure}, top@k={topk}\")\n",
    "            # Use average accuracy for this measure\n",
    "            measure_avg = avg_accuracy[avg_accuracy[\"measure\"] == measure][\"overall_accuracy\"].mean()\n",
    "            accuracy = measure_avg if not np.isnan(measure_avg) else avg_accuracy[\"overall_accuracy\"].mean()\n",
    "        else:\n",
    "            accuracy = acc_match.iloc[0][\"overall_accuracy\"]\n",
    "        \n",
    "        # Find all questions for this combination\n",
    "        combo_data = full_df[\n",
    "            (full_df[\"rcond\"] == rcond) & \n",
    "            (full_df[\"measure\"] == measure) & \n",
    "            (full_df[\"top@k\"] == topk)\n",
    "        ]\n",
    "        \n",
    "        if len(combo_data) == 0:\n",
    "            print(f\"  • Warning: No question data found for combination: rcond={rcond}, measure={measure}, top@k={topk}\")\n",
    "            # Use data from a different combination but with the same questions\n",
    "            any_combo_data = full_df[\n",
    "                (full_df[\"measure\"] == measure) & \n",
    "                (full_df[\"top@k\"] == topk)\n",
    "            ]\n",
    "            if len(any_combo_data) > 0:\n",
    "                combo_data = any_combo_data.copy()\n",
    "            else:\n",
    "                combo_data = full_df.copy()\n",
    "            \n",
    "            # Take only unique questions\n",
    "            combo_data = combo_data.drop_duplicates(subset=question_key_cols)\n",
    "        \n",
    "        # Update the parameters and accuracy\n",
    "        combo_data = combo_data.copy()\n",
    "        combo_data[\"rcond\"] = rcond\n",
    "        combo_data[\"measure\"] = measure\n",
    "        combo_data[\"top@k\"] = topk\n",
    "        combo_data[\"overall_accuracy\"] = accuracy\n",
    "        \n",
    "        # Add to results\n",
    "        result_parts.append(combo_data)\n",
    "    \n",
    "    # Combine all parts\n",
    "    clean_df = pd.concat(result_parts, ignore_index=True)\n",
    "    \n",
    "    # Step 7: Verify we have exactly 60 combinations\n",
    "    final_combos = clean_df.groupby(group_cols).size().reset_index(name=\"count\")\n",
    "    print(f\"\\nFinal check: {len(final_combos)} unique combinations\")\n",
    "    \n",
    "    if len(final_combos) == 60:\n",
    "        print(\"✓ Success! Exactly 60 unique combinations as expected.\")\n",
    "    else:\n",
    "        print(f\"Warning: Expected 60 combinations but found {len(final_combos)}.\")\n",
    "    \n",
    "    # Step 8: Save the clean dataset\n",
    "    clean_df.to_csv(output_file, index=False)\n",
    "    file_size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
    "    print(f\"\\nSuccessfully saved merged data to: {output_file}\")\n",
    "    print(f\"  • Output file size: {file_size_mb:.2f} MB\")\n",
    "    print(\"  • Merge operation completed successfully\")\n",
    "    \n",
    "    return clean_df\n",
    "\n",
    "# Execute the function\n",
    "if __name__ == \"__main__\":\n",
    "    input_pattern = \"../Outer_Correlation/new_outer_correlation_results_per_section/gram7_past_tense_results-*.csv\"\n",
    "    output_file = \"../Outer_Correlation/new_outer_correlation_results_per_section/gram7_past_tense_results.csv\"\n",
    "    merge_and_clean_results(input_pattern, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collective-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Outer_Correlation/new_outer_correlation_results_per_section/gram7_past_tense_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stainless-israel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>word3</th>\n",
       "      <th>true_word</th>\n",
       "      <th>category</th>\n",
       "      <th>category_type</th>\n",
       "      <th>candidate_1</th>\n",
       "      <th>candidate_2</th>\n",
       "      <th>candidate_3</th>\n",
       "      <th>candidate_4</th>\n",
       "      <th>...</th>\n",
       "      <th>candidate_7</th>\n",
       "      <th>candidate_8</th>\n",
       "      <th>candidate_9</th>\n",
       "      <th>candidate_10</th>\n",
       "      <th>freq_subset</th>\n",
       "      <th>quantile</th>\n",
       "      <th>rcond</th>\n",
       "      <th>measure</th>\n",
       "      <th>top@k</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dancing</td>\n",
       "      <td>danced</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>decreased</td>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>increasing</td>\n",
       "      <td>reducing</td>\n",
       "      <td>decreased</td>\n",
       "      <td>increased</td>\n",
       "      <td>...</td>\n",
       "      <td>reduce</td>\n",
       "      <td>improving</td>\n",
       "      <td>increase</td>\n",
       "      <td>doubled</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>naive_cosine</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dancing</td>\n",
       "      <td>danced</td>\n",
       "      <td>describing</td>\n",
       "      <td>described</td>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>described</td>\n",
       "      <td>ran</td>\n",
       "      <td>looked</td>\n",
       "      <td>appeared</td>\n",
       "      <td>...</td>\n",
       "      <td>came</td>\n",
       "      <td>noted</td>\n",
       "      <td>felt</td>\n",
       "      <td>called</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>naive_cosine</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dancing</td>\n",
       "      <td>danced</td>\n",
       "      <td>enhancing</td>\n",
       "      <td>enhanced</td>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>enhance</td>\n",
       "      <td>improving</td>\n",
       "      <td>enhanced</td>\n",
       "      <td>improve</td>\n",
       "      <td>...</td>\n",
       "      <td>improved</td>\n",
       "      <td>strengthen</td>\n",
       "      <td>expanding</td>\n",
       "      <td>promoting</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>naive_cosine</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dancing</td>\n",
       "      <td>danced</td>\n",
       "      <td>falling</td>\n",
       "      <td>fell</td>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>fell</td>\n",
       "      <td>went</td>\n",
       "      <td>came</td>\n",
       "      <td>hit</td>\n",
       "      <td>...</td>\n",
       "      <td>coming</td>\n",
       "      <td>were</td>\n",
       "      <td>cut</td>\n",
       "      <td>had</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>naive_cosine</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dancing</td>\n",
       "      <td>danced</td>\n",
       "      <td>feeding</td>\n",
       "      <td>fed</td>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>drove</td>\n",
       "      <td>ran</td>\n",
       "      <td>threw</td>\n",
       "      <td>brought</td>\n",
       "      <td>...</td>\n",
       "      <td>spoke</td>\n",
       "      <td>looked</td>\n",
       "      <td>picked</td>\n",
       "      <td>turned</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.053319</td>\n",
       "      <td>naive_cosine</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88915</th>\n",
       "      <td>writing</td>\n",
       "      <td>wrote</td>\n",
       "      <td>striking</td>\n",
       "      <td>struck</td>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>struck</td>\n",
       "      <td>said</td>\n",
       "      <td>saw</td>\n",
       "      <td>noted</td>\n",
       "      <td>...</td>\n",
       "      <td>came</td>\n",
       "      <td>appeared</td>\n",
       "      <td>showed</td>\n",
       "      <td>gave</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.086893</td>\n",
       "      <td>mahalanobis_shifted_cosine</td>\n",
       "      <td>10</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88916</th>\n",
       "      <td>writing</td>\n",
       "      <td>wrote</td>\n",
       "      <td>swimming</td>\n",
       "      <td>swam</td>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>swam</td>\n",
       "      <td>swim</td>\n",
       "      <td>swimmer</td>\n",
       "      <td>swimmers</td>\n",
       "      <td>...</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>drowned</td>\n",
       "      <td>swimming_pool</td>\n",
       "      <td>freestyle</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.086893</td>\n",
       "      <td>mahalanobis_shifted_cosine</td>\n",
       "      <td>10</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88917</th>\n",
       "      <td>writing</td>\n",
       "      <td>wrote</td>\n",
       "      <td>taking</td>\n",
       "      <td>took</td>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>took</td>\n",
       "      <td>said</td>\n",
       "      <td>take</td>\n",
       "      <td>says</td>\n",
       "      <td>...</td>\n",
       "      <td>had</td>\n",
       "      <td>put</td>\n",
       "      <td>left</td>\n",
       "      <td>made</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.086893</td>\n",
       "      <td>mahalanobis_shifted_cosine</td>\n",
       "      <td>10</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88918</th>\n",
       "      <td>writing</td>\n",
       "      <td>wrote</td>\n",
       "      <td>thinking</td>\n",
       "      <td>thought</td>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>thought</td>\n",
       "      <td>said</td>\n",
       "      <td>says</td>\n",
       "      <td>told</td>\n",
       "      <td>...</td>\n",
       "      <td>believe</td>\n",
       "      <td>called</td>\n",
       "      <td>added</td>\n",
       "      <td>say</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.086893</td>\n",
       "      <td>mahalanobis_shifted_cosine</td>\n",
       "      <td>10</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88919</th>\n",
       "      <td>writing</td>\n",
       "      <td>wrote</td>\n",
       "      <td>walking</td>\n",
       "      <td>walked</td>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>walked</td>\n",
       "      <td>walk</td>\n",
       "      <td>ran</td>\n",
       "      <td>struck</td>\n",
       "      <td>...</td>\n",
       "      <td>went</td>\n",
       "      <td>saw</td>\n",
       "      <td>told</td>\n",
       "      <td>left</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.086893</td>\n",
       "      <td>mahalanobis_shifted_cosine</td>\n",
       "      <td>10</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88920 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word1   word2       word3  true_word          category category_type  \\\n",
       "0      dancing  danced  decreasing  decreased  gram7-past-tense     syntactic   \n",
       "1      dancing  danced  describing  described  gram7-past-tense     syntactic   \n",
       "2      dancing  danced   enhancing   enhanced  gram7-past-tense     syntactic   \n",
       "3      dancing  danced     falling       fell  gram7-past-tense     syntactic   \n",
       "4      dancing  danced     feeding        fed  gram7-past-tense     syntactic   \n",
       "...        ...     ...         ...        ...               ...           ...   \n",
       "88915  writing   wrote    striking     struck  gram7-past-tense     syntactic   \n",
       "88916  writing   wrote    swimming       swam  gram7-past-tense     syntactic   \n",
       "88917  writing   wrote      taking       took  gram7-past-tense     syntactic   \n",
       "88918  writing   wrote    thinking    thought  gram7-past-tense     syntactic   \n",
       "88919  writing   wrote     walking     walked  gram7-past-tense     syntactic   \n",
       "\n",
       "      candidate_1 candidate_2 candidate_3 candidate_4  ... candidate_7  \\\n",
       "0      increasing    reducing   decreased   increased  ...      reduce   \n",
       "1       described         ran      looked    appeared  ...        came   \n",
       "2         enhance   improving    enhanced     improve  ...    improved   \n",
       "3            fell        went        came         hit  ...      coming   \n",
       "4           drove         ran       threw     brought  ...       spoke   \n",
       "...           ...         ...         ...         ...  ...         ...   \n",
       "88915      struck        said         saw       noted  ...        came   \n",
       "88916        swam        swim     swimmer    swimmers  ...  volleyball   \n",
       "88917        took        said        take        says  ...         had   \n",
       "88918     thought        said        says        told  ...     believe   \n",
       "88919      walked        walk         ran      struck  ...        went   \n",
       "\n",
       "      candidate_8    candidate_9 candidate_10 freq_subset quantile     rcond  \\\n",
       "0       improving       increase      doubled       30000     0.01  0.053319   \n",
       "1           noted           felt       called       30000     0.01  0.053319   \n",
       "2      strengthen      expanding    promoting       30000     0.01  0.053319   \n",
       "3            were            cut          had       30000     0.01  0.053319   \n",
       "4          looked         picked       turned       30000     0.01  0.053319   \n",
       "...           ...            ...          ...         ...      ...       ...   \n",
       "88915    appeared         showed         gave       30000     0.50  0.086893   \n",
       "88916     drowned  swimming_pool    freestyle       30000     0.50  0.086893   \n",
       "88917         put           left         made       30000     0.50  0.086893   \n",
       "88918      called          added          say       30000     0.50  0.086893   \n",
       "88919         saw           told         left       30000     0.50  0.086893   \n",
       "\n",
       "                          measure  top@k overall_accuracy  \n",
       "0                    naive_cosine      1         0.778003  \n",
       "1                    naive_cosine      1         0.778003  \n",
       "2                    naive_cosine      1         0.778003  \n",
       "3                    naive_cosine      1         0.778003  \n",
       "4                    naive_cosine      1         0.778003  \n",
       "...                           ...    ...              ...  \n",
       "88915  mahalanobis_shifted_cosine     10         0.964912  \n",
       "88916  mahalanobis_shifted_cosine     10         0.964912  \n",
       "88917  mahalanobis_shifted_cosine     10         0.964912  \n",
       "88918  mahalanobis_shifted_cosine     10         0.964912  \n",
       "88919  mahalanobis_shifted_cosine     10         0.964912  \n",
       "\n",
       "[88920 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "amended-stick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7780027 , 0.95006748, 0.96558704, 0.96963563, 0.78272605,\n",
       "       0.93049933, 0.9439946 , 0.95883941, 0.77125506, 0.9291498 ,\n",
       "       0.95276653, 0.96423752, 0.93049933, 0.93117409, 0.95209177,\n",
       "       0.78205128, 0.94601889, 0.95951417, 0.77327935, 0.9534413 ,\n",
       "       0.96491228, 0.93184885, 0.94871795, 0.96018893, 0.77732794,\n",
       "       0.93522267, 0.95681511])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overall_accuracy'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "noted-relative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall_accuracy\n",
       "0.778003    7410\n",
       "0.969636    7410\n",
       "0.950067    7410\n",
       "0.965587    7410\n",
       "0.958839    4446\n",
       "0.964238    4446\n",
       "0.771255    4446\n",
       "0.931174    4446\n",
       "0.943995    4446\n",
       "0.782726    4446\n",
       "0.930499    2964\n",
       "0.782051    2964\n",
       "0.930499    2964\n",
       "0.952767    2964\n",
       "0.964912    2964\n",
       "0.935223    1482\n",
       "0.777328    1482\n",
       "0.960189    1482\n",
       "0.948718    1482\n",
       "0.931849    1482\n",
       "0.959514    1482\n",
       "0.953441    1482\n",
       "0.773279    1482\n",
       "0.929150    1482\n",
       "0.946019    1482\n",
       "0.952092    1482\n",
       "0.956815    1482\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overall_accuracy'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "first-algebra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overall_accuracy'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8.3",
   "language": "python",
   "name": "python3.8.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
